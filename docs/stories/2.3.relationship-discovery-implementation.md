# Story 2.3: Relationship Discovery Implementation

## Status: Done

## Story

**As a** system developer,\
**I want** to implement the relationship discovery flow that combines graph traversal and vector search to find related companies,\
**so that** users can discover companies with similar business patterns, competitive relationships, or supply chain connections

## Acceptance Criteria

1. The system must implement a hybrid retrieval component (FR-B1) that combines Personalized PageRank (PPR) graph traversal with vector search
2. PPR must be executed on the existing knowledge graph using igraph library with configurable parameters from Winston's specifications
3. The hybrid retriever must merge and deduplicate results from both graph and vector sources
4. The system must implement the existing reranking component (FR-B2) to reorder hybrid results by relevance, with explicit reranking step between hybrid retrieval and fact filtering
5. The system must implement a fact filtering component (FR-B3) using DeepSeek V3 based on the filter_deepseek-chat-instruct.json logic
6. The system must implement a structured answer generator (FR-B4) that produces relationship discovery results with:
   - Company names and descriptions
   - Similarity scores (0-1 range)
   - Relevance levels determined dynamically by LLM based on NFR2 business hierarchy (direct competitors > similar products > upstream/downstream)
   - Source citations from both graph and vector data
7. The complete relationship discovery flow must integrate with the existing router.py from Story 2.1
8. API endpoints must be created to expose the relationship discovery functionality via FastAPI
9. Response time targets should be monitored and optimized during development
10. All components must follow the existing adapter pattern and project structure
11. Unit tests must achieve 100% coverage for core logic
12. Integration tests must validate the end-to-end flow from query to structured answer
13. All code must follow the TDD workflow and pass quality checks

## Tasks / Subtasks

- [ ] Task 1: Implement PPR Algorithm for Graph Traversal (AC: 1, 2, 10)
  - [ ] Create `/tests/unit/test_ppr.py` with failing tests for PPR algorithm
  - [ ] Create `/src/components/ppr.py` implementing PersonalizedPageRank class
  - [ ] Integrate with existing KnowledgeGraphConstructor's igraph structure
  - [ ] Implement configurable PPR parameters in `/config/settings.py`:
    - Damping factor: 0.85 (academic/industry standard)
    - Tolerance: 1e-6 (convergence precision)
    - Max iterations: 100
  - [ ] Add support for multi-hop traversal (configurable max hops)
  - [ ] Ensure tests pass with graph traversal functionality
  **Expected Output**: PPR component that accepts entity names and returns related entities with scores

- [ ] Task 2: Create Hybrid Retriever Component (AC: 1, 3, 10)
  - [ ] Write failing tests for hybrid retriever in `/tests/unit/test_hybrid_retriever.py`
  - [ ] Create `/src/components/hybrid_retriever.py` implementing HybridRetriever class
  - [ ] Integrate PPR component for graph-based retrieval
  - [ ] Integrate existing VectorRetriever for embedding-based retrieval
  - [ ] Implement result merging with Min-Max score normalization:
    - Vector scores: normalize to [0,1] range
    - PPR scores: normalize using (score - min)/(max - min) to [0,1]
  - [ ] Add deduplication logic based on company names
  - [ ] Configure fusion weights in `/config/settings.py`:
    - Graph weight (W_g): 0.5
    - Vector weight (W_v): 0.5
    - Fusion formula: Final_Score = (Graph_Score * W_g) + (Vector_Score * W_v)
  **Expected Output**: HybridRetriever that combines graph and vector search results

- [ ] Task 2.5: Implement Explicit Reranking Integration (AC: 4)
  - [ ] Write failing tests for reranking integration in `/tests/unit/test_reranking_integration.py`
  - [ ] Integrate existing Ranker component from Story 2.2 between hybrid retrieval and fact filtering
  - [ ] Ensure hybrid retrieval results are passed to reranker before fact filtering
  - [ ] Configure reranking parameters in `/config/settings.py`
  - [ ] Add reranking step to pipeline flow documentation
  **Expected Output**: Explicit reranking step integrated in the pipeline flow

- [ ] Task 3: Implement Fact Filtering Component (AC: 5, 10)
  - [ ] Write failing tests for fact filter in `/tests/unit/test_fact_filter.py`
  - [ ] Create `/src/components/fact_filter.py` implementing FactFilter class
  - [ ] Parse and understand filter_deepseek-chat-instruct.json structure
  - [ ] Design fact filtering prompt template and add to `/config/prompts.yaml`
  - [ ] Integrate with DeepSeek adapter for LLM-based filtering
  - [ ] Implement quality score calculation as per reference implementation
  - [ ] Ensure all filtering tests pass
  **Expected Output**: Component that filters irrelevant facts from relationship results

- [ ] Task 4: Implement Relationship Answer Generator (AC: 6, 10)
  - [ ] Write failing tests for relationship synthesizer in `/tests/unit/test_relationship_synthesizer.py`
  - [ ] Create `/src/components/relationship_synthesizer.py` implementing RelationshipSynthesizer class
  - [ ] Design structured output format with company info, scores, and relevance levels
  - [ ] Implement LLM-based relevance level determination per Winston's guidance:
    - NO hardcoded thresholds
    - LLM dynamically assigns levels based on NFR2 business hierarchy
    - Direct competitors > Similar products > Upstream/downstream
  - [ ] Add relationship discovery prompt to `/config/prompts.yaml` based on rag_qa_chinse_companies.py
  - [ ] Integrate with DeepSeek adapter for answer generation
  - [ ] Support bilingual (Chinese/English) output
  **Expected Output**: Component that generates structured relationship discovery answers

- [ ] Task 5: Create Relationship Discovery Pipeline (AC: 7, 9)
  - [ ] Write integration tests for complete pipeline in `/tests/integration/test_relationship_pipeline.py`
  - [ ] Create `/src/pipeline/relationship_pipeline.py` orchestrating all components
  - [ ] Integrate with IntentRouter to receive relationship_discovery queries
  - [ ] Implement proper error handling for graph traversal failures
  - [ ] Add performance monitoring and logging
  - [ ] Monitor and optimize end-to-end latency during development
  **Expected Output**: Complete pipeline from query to structured relationship answer

- [ ] Task 6: Extend FastAPI Endpoints (AC: 8, 13)
  - [ ] Write API tests in `/tests/api/test_relationship_endpoints.py`
  - [ ] Extend `/src/server/main.py` with relationship discovery endpoint
  - [ ] Implement security measures:
    - Static API Key authentication (X-API-Key header)
    - Rate limiting: 20 requests per minute
    - Input validation using Pydantic models
  - [ ] Implement POST `/api/v1/relationships` endpoint
  - [ ] Add request/response models for relationship queries
  - [ ] Implement proper error responses for relationship-specific errors
  - [ ] Add API documentation with relationship discovery examples
  **Expected Output**: RESTful API endpoint for relationship discovery queries

- [ ] Task 7: Handle Edge Cases and Special Scenarios (AC: 12, 13)
  - [ ] Write tests for edge cases (company not in graph, isolated nodes, empty results)
  - [ ] Implement graceful handling when PPR returns no results
  - [ ] Handle FR12(b) - no related companies found scenarios
  - [ ] Add input validation for relationship queries
  - [ ] Ensure proper error messages in both Chinese and English
  **Expected Output**: Robust error handling for all relationship discovery scenarios

- [ ] Task 8: Performance Optimization and Final Testing (AC: 9, 11, 12, 13)
  - [ ] Run performance benchmarks for PPR on full graph
  - [ ] Optimize graph traversal with caching strategies
  - [ ] Implement result caching for frequently queried companies
  - [ ] Run full test suite with coverage report
  - [ ] Execute performance tests with various graph sizes
  - [ ] Run code quality checks (ruff, mypy)
  **Expected Output**: Optimized pipeline meeting all performance requirements

## Dev Notes

### Previous Story Insights
Story 2.1 implemented the IntentRouter which classifies queries as "fact_qa" or "relationship_discovery". The router returns intent_type="relationship_discovery" for queries containing keywords like "相似", "关联", "类似", "竞品", "上下游". Story 2.2 implemented the fact-based Q&A flow with VectorRetriever, Ranker, and AnswerSynthesizer components that can be partially reused.

### Architecture Context
[Source: architecture/2-核心架构组件与交互流程.md]
This story implements the relationship discovery branch of the query flow, utilizing both the knowledge graph (igraph) and vector database (LanceDB) for hybrid retrieval.

### Technology Stack
[Source: architecture/1-架构概述与核心原则.md]
- **Graph Library**: python-igraph ~0.11.9 (for PPR calculations)
- **Vector Database**: LanceDB v0.24.0 (already implemented)
- **Reranker Model**: Qwen/Qwen3-Reranker-4B (reuse from Story 2.2)
- **LLM**: DeepSeek (deepseek-chat) for filtering and synthesis
- **API Framework**: FastAPI ~0.115.6
- **Security**: API Key authentication, rate limiting via FastAPI middleware

### Component Specifications

**PPR (Personalized PageRank)** [Source: architecture/2-核心架构组件与交互流程.md, Winston's specs]
- Location: `/src/components/ppr.py`
- Uses igraph library for graph computations
- Implements standard PPR algorithm with Winston's parameters:
  - Damping factor: 0.85 (configurable)
  - Tolerance: 1e-6
  - Max iterations: 100
- Returns ranked entities based on graph proximity

**Hybrid Retriever** [Source: architecture/2-核心架构组件与交互流程.md, Winston's specs]
- Location: `/src/components/hybrid_retriever.py`
- Combines PPR graph traversal with vector search
- Score normalization using Min-Max scaling to [0,1] range
- Fusion formula: Final_Score = (Graph_Score * 0.5) + (Vector_Score * 0.5)
- Configurable weights in settings.py

**Fact Filter** [Source: PRD - FR-B3]
- Location: `/src/components/fact_filter.py`
- Reference: `/reserved/filter_deepseek-chat-instruct.json`
- Uses DeepSeek to filter irrelevant facts
- Implements quality scoring mechanism

**Relationship Synthesizer** [Source: PRD - FR-B4, Winston's specs]
- Location: `/src/components/relationship_synthesizer.py`
- Reference: `/reserved/rag_qa_chinse_companies.py`
- Generates structured answers with LLM-determined relevance levels
- LLM dynamically assigns relevance_level based on NFR2 hierarchy:
  - Direct competitors > Similar products > Upstream/downstream
  - NO hardcoded thresholds - intelligent business logic evaluation

### Existing Components to Reuse

**From Story 2.2:**
- `Ranker` class (`/src/components/ranker.py`) - Can be reused for FR-B2
- `DeepSeekAdapter` (`/src/adapters/deepseek_adapter.py`) - For LLM operations
- `VectorRetriever` (`/src/components/retriever.py`) - For vector search portion

**From Epic 1:**
- `KnowledgeGraphConstructor` (`/src/components/knowledge_graph_constructor.py`) - Contains the igraph instance
- Graph stored at `./output/graph/knowledge_graph.graphml`

### Implementation Details

**FR-B1 (Hybrid Retrieval)**:
- Execute PPR starting from query company entity
- Perform vector search in parallel
- Normalize scores:
  - Vector scores: map to [0,1] range
  - PPR scores: Min-Max normalization to [0,1]
- Merge using fusion formula: Final = (Graph * 0.5) + (Vector * 0.5)
- Deduplicate based on company names

**FR-B2 (Reranking)**:
- Reuse existing Ranker component from Story 2.2
- Apply same reranking logic to hybrid results

**FR-B3 (Fact Filtering)**:
- Implement based on `/reserved/filter_deepseek-chat-instruct.json`
- Filter facts to keep only relevant ones
- Calculate quality scores as shown in the JSON examples

**FR-B4 (Structured Answer Generation)**:
- Use prompt pattern from `/reserved/rag_qa_chinese_companies.py`
- Generate answers with company names, descriptions, and scores
- LLM determines relevance_level based on business logic:
  - Analyze relationship type against NFR2 hierarchy
  - Direct competitors → high relevance
  - Similar products → medium relevance
  - Upstream/downstream → lower relevance
  - NO hardcoded score thresholds

### API Endpoint Design
```
POST /api/v1/relationships
Request:
{
  "query": "string",
  "company": "string",
  "max_results": "integer (default: 10)",
  "min_relevance": "string (high/medium/low, default: low)"
}

Response:
{
  "related_companies": [
    {
      "company_name": "string",
      "description": "string",
      "similarity_score": "float (0-1)",
      "relevance_level": "string (high/medium/low)",
      "relationship_type": "string",
      "sources": [
        {
          "type": "graph/vector",
          "content": "string",
          "score": "float"
        }
      ]
    }
  ],
  "intent": "relationship_discovery",
  "query_company": "string",
  "processing_time_ms": "integer"
}
```

### Configuration Requirements
Add to `/config/settings.py`:
- `ppr_damping_factor`: 0.85 (Winston's standard)
- `ppr_max_iterations`: 100
- `ppr_tolerance`: 1e-6
- `hybrid_graph_weight`: 0.5 (W_g)
- `hybrid_vector_weight`: 0.5 (W_v)
- `relationship_max_results`: 10
- `api_key`: Static API key for authentication
- `rate_limit_per_minute`: 20

### Performance Considerations
- PPR computation on large graphs can be expensive
- Consider caching PPR results for frequently queried companies
- Batch processing for fact filtering to optimize DeepSeek API calls
- Monitor performance metrics during development and optimize as needed
- Implement result caching for frequently accessed relationships

### Error Handling Requirements
- Handle FR12(b): No related companies found
- Handle graph loading failures gracefully
- Handle isolated nodes in graph (no connections)
- Provide meaningful error messages when company not in graph

### Security Requirements
[Source: Winston's specifications]

**Authentication**:
- Static API Key authentication via X-API-Key header
- Keys stored securely in environment variables
- Validate all incoming requests

**Rate Limiting**:
- 20 requests per minute per API key
- Implement via FastAPI middleware
- Return 429 status when limit exceeded

**Input Validation**:
- Use Pydantic models for all request/response validation
- Sanitize company names and queries
- Reject oversized requests

**Data Access Control**:
- Ensure graph data is read-only during queries
- No modification operations exposed via API
- Log all access attempts

### Test Data Requirements

**Sample Graph Data**:
```python
# Mock graph structure for testing
test_graph = {
    "nodes": [
        {"id": "公司A", "type": "company", "industry": "AI"},
        {"id": "公司B", "type": "company", "industry": "AI"},
        {"id": "公司C", "type": "company", "industry": "供应链"}
    ],
    "edges": [
        {"source": "公司A", "target": "公司B", "relationship": "竞品"},
        {"source": "公司A", "target": "公司C", "relationship": "上游"}
    ]
}
```

**Mock Vector Search Results**:
```python
test_vector_results = [
    {"company": "公司D", "score": 0.85, "description": "AI芯片制造商"},
    {"company": "公司E", "score": 0.72, "description": "云计算服务商"}
]
```

**Expected Outputs**:
```python
expected_output = {
    "related_companies": [
        {
            "company_name": "公司B",
            "description": "直接竞争对手，同为AI领域",
            "similarity_score": 0.9,
            "relevance_level": "high",  # LLM determined
            "relationship_type": "竞品",
            "sources": [{"type": "graph", "content": "...", "score": 0.9}]
        }
    ]
}
```

## Testing

Testing must follow the mandatory TDD workflow with tests written before implementation.

**Test Files Structure**:
```
tests/
├── unit/
│   ├── test_ppr.py                    # PPR algorithm tests
│   ├── test_hybrid_retriever.py       # HybridRetriever tests
│   ├── test_fact_filter.py            # FactFilter tests
│   └── test_relationship_synthesizer.py # RelationshipSynthesizer tests
├── integration/
│   └── test_relationship_pipeline.py   # End-to-end pipeline tests
└── api/
    └── test_relationship_endpoints.py  # API endpoint tests
```

**Test Commands**:
```bash
# Unit tests
pytest tests/unit/test_ppr.py -v
pytest tests/unit/test_hybrid_retriever.py -v
pytest tests/unit/test_fact_filter.py -v
pytest tests/unit/test_relationship_synthesizer.py -v

# Integration tests
pytest tests/integration/test_relationship_pipeline.py -v

# API tests
pytest tests/api/test_relationship_endpoints.py -v

# Coverage report
pytest tests/ --cov=src.components --cov=src.pipeline --cov-report=html

# Performance tests (create if needed)
pytest tests/integration/test_relationship_pipeline.py -k performance
```

**Test Scenarios to Cover**:
1. **PPR Tests**:
   - Single entity traversal
   - Multi-hop relationships
   - Damping factor effects
   - Convergence criteria
   - Empty graph handling

2. **Hybrid Retrieval Tests**:
   - Graph-only results
   - Vector-only results
   - Merged results with deduplication
   - Score normalization
   - Weight configuration effects

3. **Fact Filtering Tests**:
   - Relevant fact retention
   - Irrelevant fact removal
   - Quality score calculation
   - Empty input handling
   - Malformed fact handling

4. **Relationship Synthesis Tests**:
   - Structured output format
   - Relevance level assignment
   - Bilingual output support
   - Source citation formatting
   - Multiple company handling

5. **Pipeline Tests**:
   - End-to-end query processing
   - Component integration
   - Error propagation
   - Performance benchmarks
   - Concurrent request handling

## Change Log

| Date | Version | Description | Author |
| :--- | :------ | :---------- | :----- |
| 2025-01-07 | 1.0 | Initial story creation based on FR-B1, FR-B2, FR-B3, FR-B4 | Scrum Master (Bob) |

## Dev Agent Record

### Agent Model Used: claude-3-5-sonnet-20241022

### Debug Log References

### Completion Notes List

### File List

## QA Results