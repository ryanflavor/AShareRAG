# Story 1.2: Named Entity Recognition

## Status: Reviewed

## Story

**As a** system developer,  
**I want** to implement Named Entity Recognition (NER) that extracts all named entities from text chunks using LLM,  
**so that** we can identify key entities for building the knowledge graph relationships

## Acceptance Criteria

1. LLM Adapter is implemented with NER functionality using DeepSeek V3 API
2. NER prompt template is loaded from config/prompts.yaml following the structure in ner_chinese.py
3. Knowledge Graph Constructor component is created to orchestrate NER processing
4. System processes each text chunk from Data Ingestor and extracts all named entities
5. NER results are returned in JSON format with a list of entity strings
6. Proper error handling for LLM API failures and malformed responses
7. Unit tests exist for all NER functionality following TDD approach
8. Integration tests verify end-to-end NER processing
9. Code passes ruff format checks

## Tasks / Subtasks

- [ ] Task 1: Create NER prompt configuration (AC: 2)
  - [ ] Add NER section to config/prompts.yaml with system prompt
  - [ ] Include one-shot example from ner_chinese.py
  - [ ] Define prompt template structure with ${passage} placeholder

- [ ] Task 2: Implement LLM Adapter with NER functionality (AC: 1, 5, 6)
  - [ ] Create src/adapters/__init__.py
  - [ ] Create src/adapters/llm_adapter.py
  - [ ] Implement DeepSeek V3 client initialization
  - [ ] Create extract_entities() method that loads prompt and calls LLM
  - [ ] Parse JSON response and validate entity list structure
  - [ ] Add retry logic and error handling for API failures

- [ ] Task 3: Implement Knowledge Graph Constructor component (AC: 3, 4)
  - [ ] Create src/components/knowledge_graph_constructor.py
  - [ ] Implement process_documents() method that accepts documents from Data Ingestor
  - [ ] For each document, call LLM Adapter's extract_entities()
  - [ ] Return mapping of document to extracted entities
  - [ ] Add logging for processing progress

- [ ] Task 4: Write comprehensive unit tests (AC: 7)
  - [ ] Create tests/unit/test_llm_adapter.py
  - [ ] Test successful entity extraction with mock LLM response
  - [ ] Test handling of empty text input
  - [ ] Test malformed JSON response handling
  - [ ] Test API failure retry logic
  - [ ] Create tests/unit/test_knowledge_graph_constructor.py
  - [ ] Test document processing flow
  - [ ] Test error propagation

- [ ] Task 5: Write integration tests (AC: 8)
  - [ ] Create tests/integration/__init__.py
  - [ ] Create tests/integration/test_ner_pipeline.py
  - [ ] Test full pipeline from Data Ingestor to NER output
  - [ ] Verify entity extraction from sample corpus data
  - [ ] Test with multiple documents

- [ ] Task 6: Setup code quality checks (AC: 9)
  - [ ] Run ruff format on all new code
  - [ ] Ensure all tests pass with 100% success rate
  - [ ] Update settings.py if new environment variables needed

## Dev Notes

### Technology Stack (Source: architecture/1-架构概述与核心原则.md)
- **LLM Provider**: DeepSeek V3 (designated for NER and RE tasks)
- **Python**: ~3.10
- **Testing**: Pytest ~8.2.2 with strict TDD approach
- **Config Management**: Pydantic Settings for environment variables
- **Code Quality**: ruff for formatting

### Component Architecture (Source: architecture/2-核心架构组件与交互流程.md)
The Knowledge Graph Constructor (Component #2) is responsible for:
- Receiving text chunks from Data Ingestor
- Calling NER through LLM Adapter
- Later will call RE (Relation Extraction) in next story
- Outputs to igraph for graph construction

### LLM Adapter Design Principles (Source: architecture/1-架构概述与核心原则.md)
- All LLM interactions must go through adapters in src/adapters/
- Adapters encapsulate prompt management and API calls
- No direct modification of HippoRAG internals
- Follow "encapsulation and injection" pattern

### NER Prompt Template Structure (Source: reserved/ner_chinese.py)
```python
prompt_template = [
    {"role": "system", "content": ner_system},
    {"role": "user", "content": one_shot_ner_paragraph},
    {"role": "assistant", "content": one_shot_ner_output},
    {"role": "user", "content": "${passage}"},
]
```

Expected output format:
```json
{"named_entities": ["entity1", "entity2", "entity3", ...]}
```

### Entity Types to Extract (Based on one-shot example)
- Company names (公司名称)
- Stock codes (股票代码)
- Business sectors (业务板块)
- Subsidiary companies (子公司)
- Products and services (产品/服务)
- Technologies (技术)
- Application domains (应用领域)
- Key business terms

### Project Structure Updates
```
src/
├── adapters/
│   ├── __init__.py
│   └── llm_adapter.py         # New: DeepSeek V3 integration
├── components/
│   ├── __init__.py
│   ├── data_ingestor.py      # Existing from Story 1.1
│   └── knowledge_graph_constructor.py  # New: NER orchestration
config/
├── prompts.yaml               # Update: Add NER prompt section
└── settings.py                # Update: Add DeepSeek API settings
tests/
├── unit/
│   ├── test_llm_adapter.py    # New: LLM Adapter tests
│   └── test_knowledge_graph_constructor.py  # New: Component tests
└── integration/
    ├── __init__.py            # New
    └── test_ner_pipeline.py   # New: End-to-end tests
```

### Configuration Requirements
Add to .env.example and settings.py:
- DEEPSEEK_API_KEY: API key for DeepSeek V3
- DEEPSEEK_API_BASE: Base URL for DeepSeek API (default: https://api.deepseek.com/v1)
- DEEPSEEK_MODEL: Model name (default: deepseek-chat)

### Error Handling Strategy
- API timeouts: Implement exponential backoff retry (max 3 attempts)
- Malformed responses: Log error and return empty entity list
- Rate limiting: Implement request throttling if needed
- Connection errors: Graceful degradation with clear error messages

### Data Flow
1. Data Ingestor loads corpus.json → List of Documents
2. Knowledge Graph Constructor receives documents
3. For each document:
   - Extract text content
   - Call LLM Adapter's extract_entities(text)
   - Store document → entities mapping
4. Return complete entity extraction results

### Testing

Testing Standards from Architecture:
- Use pytest framework (~8.2.2)
- Unit tests in `tests/unit/`
- Integration tests in `tests/integration/`
- Follow strict TDD: write test first, then implementation
- 100% test pass rate required
- Mock external dependencies (DeepSeek API) in unit tests
- Use fixtures for test data setup

### Important Notes from Story 1.1
- Project uses uv package manager
- Configuration loaded via Pydantic Settings from environment
- Each document's text field is treated as single chunk (no splitting)
- Comprehensive error handling expected for all edge cases

## Change Log

| Date | Version | Description | Author |
| :--- | :------ | :---------- | :----- |
| 2025-01-05 | 1.0 | Initial story creation | SM (Bob) |

## Dev Agent Record

### Agent Model Used: {{Agent Model Name/Version}}

### Debug Log References

### Completion Notes List

### File List

## QA Results