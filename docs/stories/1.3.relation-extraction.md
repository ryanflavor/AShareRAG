# Story 1.3: Relation Extraction

## Status: Done

## Story

**As a** system developer,  
**I want** to implement Relation Extraction (RE) that extracts relationship triples from text chunks using LLM,  
**so that** we can build a comprehensive knowledge graph showing relationships between entities

**Parent Epic:** Epic 1 - 基础数据管道与索引构建 (Foundational Data Pipeline & Indexing)  
**Epic Scope:** FR1-FR6 (This story implements FR3: 关系抽取)

## Acceptance Criteria

1. LLM Adapter is extended with RE functionality using DeepSeek V3 API
2. RE prompt template is loaded from config/prompts.yaml following the structure in triple_extraction_chinese.py
3. Knowledge Graph Constructor is enhanced to orchestrate RE processing after NER
4. System processes each text chunk with its NER results to extract relationship triples
5. RE results are returned in JSON format with a list of triple arrays [subject, predicate, object]
6. Triples are stored in igraph format for graph construction
7. Proper error handling for LLM API failures and malformed responses
8. Unit tests exist for all RE functionality following TDD approach
9. Integration tests verify end-to-end RE processing pipeline
10. Code passes ruff format checks

## Tasks / Subtasks

- [x] Task 1: Create RE prompt configuration (AC: 2)
  - [x] Add RE section to config/prompts.yaml with system prompt
  - [x] Include one-shot example from triple_extraction_chinese.py
  - [x] Define prompt template structure with {passage} and {named_entity_json} placeholders

- [x] Task 2: Extend LLM Adapter with RE functionality (AC: 1, 5, 7)
  - [x] Add extract_relations() method to src/adapters/llm_adapter.py
  - [x] Handle typed entity format from Story 1.2.1: extract text from entity objects
  - [x] Implement prompt loading and formatting with NER results
  - [x] Convert typed entities to simple text list for prompt: `[entity["text"] for entity in entities]`
  - [x] Parse JSON response and validate triple list structure
  - [x] Add retry logic and error handling for API failures
  - [x] Ensure each triple contains at least one named entity (check against entity texts)
  - [x] Handle empty entity list gracefully (return empty triple list)
  - [x] Validate triple format (exactly 3 elements per triple)
  - [x] Handle and deduplicate duplicate triples within same document
  - [x] Add memory usage monitoring for large triple sets

- [x] Task 3: Enhance Knowledge Graph Constructor for RE (AC: 3, 4, 6)
  - [x] Update process_documents() to call RE after NER
  - [x] Pass document text and NER results to extract_relations()
  - [x] Initialize igraph object for storing triples
  - [x] Add triples to graph with proper entity and relation handling
  - [x] Add logging for RE processing progress

- [x] Task 4: Write comprehensive unit tests (AC: 8)
  - [x] Update tests/unit/test_llm_adapter.py
  - [x] Test successful relation extraction with mock LLM response
  - [x] Test handling of typed entities from Story 1.2.1 format
  - [x] Test conversion of typed entities to text list for prompt
  - [x] Test handling of empty entity list
  - [x] Test malformed JSON response handling
  - [x] Test validation that triples contain named entities (using entity texts)
  - [x] Update tests/unit/test_knowledge_graph_constructor.py
  - [x] Test full NER+RE processing flow with typed entities
  - [x] Test igraph construction from triples
  - [x] Test entity list formatting from typed objects to JSON
  - [x] Test handling of duplicate triples
  - [x] Test graph vertex deduplication
  - [x] Test self-referential relations handling
  - [x] Test large document sets (performance/memory)

- [x] Task 5: Write integration tests (AC: 9)
  - [x] Update tests/integration/test_ner_pipeline.py to test_knowledge_graph_pipeline.py
  - [x] Test full pipeline from Data Ingestor to RE output
  - [x] Verify relation extraction from sample corpus data
  - [x] Test graph construction with multiple documents
  - [x] Verify entity deduplication in graph

- [x] Task 6: Code quality and formatting (AC: 10)
  - [x] Run ruff format on all modified code
  - [x] Ensure all tests pass with 100% success rate
  - [x] Update prompts.yaml with proper YAML formatting

## Dev Notes

### Critical Dependency: Story 1.2.1 Must Be Completed First
**IMPORTANT**: This story depends on Story 1.2.1 (Enhanced NER with Entity Types) being completed. Story 1.2.1 changes the NER output format from simple strings to typed entities, which this story must handle correctly.

### Previous Story Insights (Source: Story 1.2 and 1.2.1)
- LLM Adapter already implemented with DeepSeek V3 client in `src/adapters/llm_adapter.py`
- Retry logic with exponential backoff already exists (max 3 attempts)
- Error handling patterns established for API failures and malformed responses
- Knowledge Graph Constructor exists at `src/components/knowledge_graph_constructor.py`
- Configuration loaded via Pydantic Settings from environment
- Project uses uv package manager
- Each document's text field is treated as single chunk (no splitting)
- **Story 1.2.1 Enhancement**: NER now returns typed entities instead of simple strings

### Entity List Formatting for RE (Updated for Typed Entities)
- NER output format (from Story 1.2.1): `[{"text": "entity1", "type": "COMPANY"}, {"text": "entity2", "type": "PRODUCT"}, ...]`
- RE input format for prompt: `{"named_entities": ["entity1", "entity2", "entity3"]}`
- The extract_relations() method must:
  1. Extract just the "text" field from each entity object
  2. Create a simple list of entity texts: `[entity["text"] for entity in entities]`
  3. Format as JSON for the prompt: `{"named_entities": entity_texts}`
- Use json.dumps() to ensure proper JSON formatting

### Entity Validation in Triples (Updated for Typed Entities)
When validating that "each triple contains at least one named entity":
- Extract entity texts from the typed format: `entity_texts = {entity["text"] for entity in entities}`
- Check if any triple element is in the entity_texts set
- This ensures compatibility with the new typed entity format from Story 1.2.1

### Technology Stack (Source: architecture/1-架构概述与核心原则.md)
- **LLM Provider**: DeepSeek V3 (designated for NER and RE tasks)
- **Graph Library**: python-igraph ~0.11.9 for knowledge graph storage
- **Python**: ~3.10
- **Testing**: Pytest ~8.2.2 with strict TDD approach
- **Config Management**: Pydantic Settings for environment variables
- **Code Quality**: ruff for formatting

### Component Architecture (Source: architecture/2-核心架构组件与交互流程.md)
The Knowledge Graph Constructor (Component #2) is responsible for:
- Receiving text chunks from Data Ingestor
- Calling NER through LLM Adapter (completed in Story 1.2)
- Calling RE through LLM Adapter (this story)
- Building the igraph graph with entities and relationships
- Outputs to downstream components for indexing

### LLM Adapter Design Principles (Source: architecture/1-架构概述与核心原则.md)
- All LLM interactions must go through adapters in src/adapters/
- Adapters encapsulate prompt management and API calls
- No direct modification of HippoRAG internals
- Follow "encapsulation and injection" pattern

### RE Prompt Template Structure (Source: reserved/triple_extraction_chinese.py)
```python
prompt_template = [
    {"role": "system", "content": ner_conditioned_re_system},
    {"role": "user", "content": ner_conditioned_re_input},
    {"role": "assistant", "content": ner_conditioned_re_output},
    {"role": "user", "content": "{passage}\n\n{named_entity_json}"},
]
```

### Required Imports
The prompt template requires the following utility:
```python
from reserved.utils.llm_utils import convert_format_to_template
```
This utility is used to convert the prompt template format for the final user message.

The system prompt explains the task of building RDF triples with requirements:
- Each triple should contain at least one named entity, preferably two
- Resolve pronouns to specific names for clarity

Expected output format:
```json
{"triples": [
    ["subject", "predicate", "object"],
    ["综艺股份", "公司代码是", "600770"],
    ["南京天悦", "是子公司", "综艺股份"],
    ...
]}
```

### Relation Types from One-Shot Example
Based on the example, common relation types include:
- Corporate relationships: "是子公司", "是参股公司"
- Business descriptions: "主营业务包括", "核心业务是"
- Product relationships: "主要产品包括"
- Domain relationships: "布局领域", "应用领域"
- Identifiers: "公司代码是", "股票代码是"
- Operations: "运营业务"

### Project Structure Updates
```
src/
├── adapters/
│   └── llm_adapter.py         # Update: Add extract_relations() method
├── components/
│   └── knowledge_graph_constructor.py  # Update: Add RE orchestration
config/
├── prompts.yaml               # Update: Add RE prompt section
tests/
├── unit/
│   ├── test_llm_adapter.py    # Update: Add RE tests
│   └── test_knowledge_graph_constructor.py  # Update: Add graph tests
└── integration/
    └── test_knowledge_graph_pipeline.py  # Rename & update: Full NER+RE tests
```

### Data Flow
1. Data Ingestor loads corpus.json → List of Documents
2. Knowledge Graph Constructor receives documents
3. For each document:
   - Extract text content
   - Call LLM Adapter's extract_entities(text) → entity list
   - Call LLM Adapter's extract_relations(text, entities) → triple list
   - Add entities and relations to igraph
4. Return complete knowledge graph

### igraph Integration Notes
- Use python-igraph ~0.11.9 (already in project dependencies)
- Create directed graph with entities as vertices
- Add edges for each relation triple
- Store relation type as edge attribute
- Handle entity deduplication when adding vertices
- Consider using vertex attributes for entity metadata

### Graph Implementation Specifications (Updated for Typed Entities)
- **Vertex ID Strategy**: Use entity name (text field) as vertex ID (ensures uniqueness)
- **Vertex Attributes**: 
  - name: Entity name from entity["text"] (string)
  - type: Entity type from entity["type"] (string) - NOW AVAILABLE from Story 1.2.1
  - first_seen: Document ID where entity first appeared
- **Edge Attributes**:
  - relation: Predicate text (string)
  - source_doc: Document ID where relation was extracted
  - confidence: Set to 1.0 for LLM-extracted relations
- **Deduplication**: Check if vertex exists before adding (igraph's add_vertices handles this)
- **Self-referential Relations**: Allowed but logged for monitoring
- **Graph Persistence**: Save as GraphML format for portability
- **Entity Type Handling**: Store the entity type from NER results as vertex attribute for downstream use

### Error Handling Strategy
- Reuse existing retry logic from LLM Adapter
- For malformed RE responses: log error and return empty triple list
- Validate that each triple has exactly 3 elements
- Validate that at least one element in each triple is a named entity
- Graceful degradation: continue processing other documents if one fails

### Testing Standards (Source: architecture/4-ai开发工作流与交付标准.md)
- Use pytest framework (~8.2.2)
- Unit tests in `tests/unit/`
- Integration tests in `tests/integration/`
- Follow strict TDD: write test first, then implementation
- 100% test pass rate required
- Mock external dependencies (DeepSeek API) in unit tests
- Use fixtures for test data setup

### Important Configuration Notes
- DeepSeek API configuration already exists from Story 1.2:
  - DEEPSEEK_API_KEY: API key for DeepSeek V3
  - DEEPSEEK_API_BASE: Base URL for DeepSeek API
  - DEEPSEEK_MODEL: Model name (default: deepseek-chat)
- No new environment variables needed for RE

### Security Considerations
- API keys are properly managed through environment variables (never hardcoded)
- The DEEPSEEK_API_KEY is loaded via Pydantic Settings from .env file
- Ensure .env file is in .gitignore to prevent accidental commits
- API key validation happens on LLM Adapter initialization
- All API errors are logged without exposing sensitive information

## Testing
- Use pytest framework (~8.2.2) 
- Unit tests must be created in `tests/unit/` directory
- Integration tests must be created in `tests/integration/` directory
- Follow strict TDD approach: write failing test first, then implementation
- All tests must pass with 100% success rate before marking story complete
- Mock all external dependencies (DeepSeek API) in unit tests
- Use pytest fixtures for test data setup and reusable components
- Test file naming convention: `test_<component_name>.py`
- Each test should be focused and test one specific behavior
- Include edge cases and error scenarios in test coverage
- Mock the convert_format_to_template utility in unit tests
- Verify prompt template formatting with actual utility in integration tests

## Change Log

| Date | Version | Description | Author |
| :--- | :------ | :---------- | :----- |
| 2025-01-06 | 1.0 | Initial story creation | SM (Bob) |

## Dev Agent Record

### Agent Model Used: claude-sonnet-4-20250514

### Debug Log References
- Verified existing implementation meets all acceptance criteria
- All 32 tests passing (8 RE-specific, 24 supporting tests)
- Code quality validation passed with ruff formatting
- Integration tests verify full NER+RE pipeline functionality

### Completion Notes List
- Story 1.3 implementation was previously completed and QA-approved
- All acceptance criteria verified as implemented:
  1. LLM Adapter extended with extract_relations() method ✅
  2. RE prompts configured in config/prompts.yaml ✅
  3. Knowledge Graph Constructor enhanced for NER+RE orchestration ✅
  4. Typed entity format from Story 1.2.1 properly handled ✅
  5. JSON triple format implemented correctly ✅
  6. igraph storage and construction working ✅
  7. Comprehensive error handling and retry logic ✅
  8. Unit tests complete with 100% pass rate ✅
  9. Integration tests verify end-to-end pipeline ✅
  10. Code passes ruff format checks ✅

### File List
- config/prompts.yaml (modified - added RE prompts section)
- src/adapters/llm_adapter.py (modified - added extract_relations method)
- src/components/knowledge_graph_constructor.py (modified - enhanced for RE processing)
- tests/unit/test_llm_adapter.py (modified - added comprehensive RE tests)
- tests/unit/test_knowledge_graph_constructor.py (modified - updated for graph construction)
- tests/integration/test_knowledge_graph_pipeline.py (renamed from test_ner_pipeline.py)

## QA Results