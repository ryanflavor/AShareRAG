#!/usr/bin/env python3
"""
éªŒè¯NERå’ŒREåŠŸèƒ½çš„å®é™…æ•ˆæœ
ä½¿ç”¨çœŸå®çš„DeepSeek APIå’Œcorpus.jsonæ•°æ®æµ‹è¯•ä¸€ä¸ªå…¬å¸çš„å‘½åå®ä½“è¯†åˆ«å’Œå…³ç³»æŠ½å–
"""

import json
import sys
import os
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.adapters import LLMAdapter
from src.components.knowledge_graph_constructor import KnowledgeGraphConstructor
from src.components.data_ingestor import DataIngestor
from config.settings import Settings


def main():
    """ä¸»å‡½æ•°ï¼šéªŒè¯NERå’ŒREåŠŸèƒ½"""

    print("ğŸ” å¼€å§‹éªŒè¯NERå’ŒREåŠŸèƒ½...")
    print("=" * 60)

    try:
        # 1. åŠ è½½é…ç½®
        print("ğŸ“‹ 1. åŠ è½½é…ç½®...")
        settings = Settings()
        print(
            f"   - DeepSeek APIé…ç½®: {'âœ… å·²é…ç½®' if settings.deepseek_api_key.startswith('sk-') else 'âŒ æœªé…ç½®'}"
        )
        print(f"   - æ¨¡å‹: {settings.deepseek_model}")

        # 2. åˆå§‹åŒ–ç»„ä»¶
        print("\nğŸ”§ 2. åˆå§‹åŒ–ç»„ä»¶...")
        llm_adapter = LLMAdapter(enable_cache=True, high_throughput=True)
        kg_constructor = KnowledgeGraphConstructor()
        data_ingestor = DataIngestor()
        print("   - LLM Adapter: âœ…")
        print("   - Knowledge Graph Constructor: âœ…")
        print("   - Data Ingestor: âœ…")

        # 3. åŠ è½½æ•°æ®
        print("\nğŸ“‚ 3. åŠ è½½corpus.jsonæ•°æ®...")
        documents = data_ingestor.load_corpus("data/corpus.json")
        print(f"   - æˆåŠŸåŠ è½½ {len(documents)} ä¸ªå…¬å¸æ–‡æ¡£")

        # 4. é€‰æ‹©æµ‹è¯•å…¬å¸ï¼ˆå–ç¬¬ä¸€ä¸ªï¼šGQYè§†è®¯ï¼‰
        test_company = documents[0]
        print(f"\nğŸ¢ 4. æµ‹è¯•å…¬å¸: {test_company.title}")
        print(f"   - æ–‡æ¡£é•¿åº¦: {len(test_company.text)} å­—ç¬¦")

        # æ˜¾ç¤ºå…¬å¸æ–‡æœ¬çš„å‰500å­—ç¬¦
        preview_text = (
            test_company.text[:500] + "..."
            if len(test_company.text) > 500
            else test_company.text
        )
        print(f"   - æ–‡æ¡£é¢„è§ˆ: {preview_text}")

        # 5. æµ‹è¯•NERåŠŸèƒ½
        print(f"\nğŸ·ï¸  5. æµ‹è¯•å‘½åå®ä½“è¯†åˆ«ï¼ˆNERï¼‰...")
        print("   å‘é€è¯·æ±‚åˆ°DeepSeek API...")

        entities = llm_adapter.extract_entities(test_company.text, include_types=True)

        print(f"   - è¯†åˆ«åˆ° {len(entities)} ä¸ªå‘½åå®ä½“:")
        for i, entity in enumerate(entities[:10], 1):  # åªæ˜¾ç¤ºå‰10ä¸ª
            print(f"     {i}. {entity['text']} ({entity['type']})")
        if len(entities) > 10:
            print(f"     ... è¿˜æœ‰ {len(entities) - 10} ä¸ªå®ä½“")

        # 6. æµ‹è¯•REåŠŸèƒ½
        print(f"\nğŸ”— 6. æµ‹è¯•å…³ç³»æŠ½å–ï¼ˆREï¼‰...")
        print("   å‘é€è¯·æ±‚åˆ°DeepSeek API...")

        relations = llm_adapter.extract_relations(test_company.text, entities)

        print(f"   - æŠ½å–åˆ° {len(relations)} ä¸ªå…³ç³»ä¸‰å…ƒç»„:")
        for i, triple in enumerate(relations[:10], 1):  # åªæ˜¾ç¤ºå‰10ä¸ª
            subject, predicate, obj = triple
            print(f"     {i}. ({subject}, {predicate}, {obj})")
        if len(relations) > 10:
            print(f"     ... è¿˜æœ‰ {len(relations) - 10} ä¸ªå…³ç³»")

        # 7. æµ‹è¯•çŸ¥è¯†å›¾è°±æ„å»º
        print(f"\nğŸ•¸ï¸  7. æµ‹è¯•çŸ¥è¯†å›¾è°±æ„å»º...")
        # è½¬æ¢Documentå¯¹è±¡ä¸ºå­—å…¸æ ¼å¼
        doc_dict = {
            "id": test_company.idx,
            "text": test_company.text,
            "title": test_company.title,
        }
        results, graph = kg_constructor.process_documents([doc_dict])

        print(f"   - å›¾è°±ç»Ÿè®¡:")
        print(f"     * é¡¶ç‚¹æ•°é‡: {graph.vcount()}")
        print(f"     * è¾¹æ•°é‡: {graph.ecount()}")

        # æ˜¾ç¤ºä¸€äº›é¡¶ç‚¹ä¿¡æ¯
        if graph.vcount() > 0:
            print(f"   - é¡¶ç‚¹ç¤ºä¾‹ (å‰5ä¸ª):")
            for i in range(min(5, graph.vcount())):
                vertex = graph.vs[i]
                name = vertex["name"]
                entity_type = vertex.attributes().get("entity_type", "æœªçŸ¥")
                print(f"     {i + 1}. {name} ({entity_type})")

        # æ˜¾ç¤ºä¸€äº›è¾¹ä¿¡æ¯
        if graph.ecount() > 0:
            print(f"   - å…³ç³»ç¤ºä¾‹ (å‰5ä¸ª):")
            for i in range(min(5, graph.ecount())):
                edge = graph.es[i]
                source_name = graph.vs[edge.source]["name"]
                target_name = graph.vs[edge.target]["name"]
                relation = edge["relation"]
                print(f"     {i + 1}. {source_name} --[{relation}]--> {target_name}")

        # 8. éªŒè¯ç»“æœè´¨é‡
        print(f"\nâœ… 8. ç»“æœè´¨é‡è¯„ä¼°:")

        # æ£€æŸ¥æ˜¯å¦è¯†åˆ«åˆ°å…¬å¸åç§°
        company_names = ["GQYè§†è®¯", "GQY", "è§†è®¯"]
        found_company = any(
            any(name.lower() in entity["text"].lower() for name in company_names)
            for entity in entities
        )
        print(f"   - å…¬å¸åç§°è¯†åˆ«: {'âœ… æˆåŠŸ' if found_company else 'âŒ å¤±è´¥'}")

        # æ£€æŸ¥æ˜¯å¦è¯†åˆ«åˆ°å…³é”®ä¸šåŠ¡è¯æ±‡
        business_keywords = ["æ˜¾ç¤º", "æ‹¼æ¥", "LED", "ç³»ç»Ÿé›†æˆ", "æ™ºæ…§åŸå¸‚"]
        found_business = any(
            any(keyword in entity["text"] for keyword in business_keywords)
            for entity in entities
        )
        print(f"   - ä¸šåŠ¡å…³é”®è¯è¯†åˆ«: {'âœ… æˆåŠŸ' if found_business else 'âŒ å¤±è´¥'}")

        # æ£€æŸ¥å…³ç³»æŠ½å–è´¨é‡
        valid_relations = sum(
            1
            for triple in relations
            if len(triple) == 3 and all(len(str(x).strip()) > 0 for x in triple)
        )
        relation_quality = valid_relations / len(relations) if relations else 0
        print(
            f"   - å…³ç³»ä¸‰å…ƒç»„è´¨é‡: {relation_quality:.1%} ({valid_relations}/{len(relations)} ä¸ªæœ‰æ•ˆ)"
        )

        # æ£€æŸ¥æ˜¯å¦åŒ…å«æœ‰æ„ä¹‰çš„å…³ç³»
        meaningful_relations = []
        for triple in relations:
            subject, predicate, obj = triple
            # æ£€æŸ¥æ˜¯å¦åŒ…å«å…¬å¸ç›¸å…³çš„å…³ç³»
            if any(name in subject or name in obj for name in company_names):
                meaningful_relations.append(triple)

        print(f"   - å…¬å¸ç›¸å…³å…³ç³»: {len(meaningful_relations)} ä¸ª")
        if meaningful_relations:
            print("     ç¤ºä¾‹:")
            for triple in meaningful_relations[:3]:
                subject, predicate, obj = triple
                print(f"       * ({subject}, {predicate}, {obj})")

        print(f"\nğŸ‰ éªŒè¯å®Œæˆï¼")
        print(f"NERæˆåŠŸè¯†åˆ« {len(entities)} ä¸ªå®ä½“ï¼ŒREæˆåŠŸæŠ½å– {len(relations)} ä¸ªå…³ç³»")
        print(f"çŸ¥è¯†å›¾è°±åŒ…å« {graph.vcount()} ä¸ªé¡¶ç‚¹å’Œ {graph.ecount()} æ¡è¾¹")

        return True

    except Exception as e:
        print(f"\nâŒ éªŒè¯è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        import traceback

        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
