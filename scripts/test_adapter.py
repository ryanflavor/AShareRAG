#!/usr/bin/env python3
"""
æµ‹è¯•é«˜æ€§èƒ½LLMé€‚é…å™¨
éªŒè¯HTTPè¿æ¥æ± å’Œç¼“å­˜ä¼˜åŒ–çš„æ•ˆæœ
"""

import time
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.adapters import LLMAdapter


def test_performance_improvement():
    """æµ‹è¯•æ€§èƒ½æ”¹è¿›æ•ˆæœ"""
    print("ğŸš€ æµ‹è¯•é«˜æ€§èƒ½LLMé€‚é…å™¨")
    print("=" * 50)

    # æµ‹è¯•æ–‡æœ¬
    test_text = """
    GQYè§†è®¯æ˜¯ä¸€å®¶ä¸“æ³¨äºæ™ºèƒ½æ‹¼æ¥æ˜¾ç¤ºäº§å“é¢†åŸŸçš„å…¬å¸ï¼Œå…¬å¸ä»£ç æ˜¯300076ã€‚
    ä¸»è¦äº§å“åŒ…æ‹¬Mini LEDæ‹¼æ¥æ˜¾ç¤ºå•å…ƒã€DLPæ‹¼æ¥æ˜¾ç¤ºå•å…ƒã€æ¶²æ™¶æ‹¼æ¥æ˜¾ç¤ºå•å…ƒã€‚
    åº”ç”¨é¢†åŸŸæ¶‰åŠåº”æ€¥ã€è½¨é“ã€å¹¿ç”µã€èƒ½æºã€äº¤é€šç­‰è¡Œä¸šã€‚
    """

    # åˆå§‹åŒ–é«˜æ€§èƒ½é€‚é…å™¨
    print("\nğŸ”§ åˆå§‹åŒ–é«˜æ€§èƒ½é€‚é…å™¨...")
    start_time = time.time()
    fast_adapter = LLMAdapter(enable_cache=True, high_throughput=True)
    init_time = time.time() - start_time
    print(f"   åˆå§‹åŒ–è€—æ—¶: {init_time:.3f}ç§’")

    # æ¸…é™¤ç¼“å­˜ä»¥ç¡®ä¿å¹²å‡€æµ‹è¯•
    fast_adapter.clear_cache()

    results = {}

    # ç¬¬ä¸€æ¬¡NERè°ƒç”¨ï¼ˆå†·å¯åŠ¨ï¼‰
    print("\nğŸ·ï¸  ç¬¬ä¸€æ¬¡NERè°ƒç”¨ï¼ˆå†·å¯åŠ¨ï¼‰...")
    start_time = time.time()
    entities1 = fast_adapter.extract_entities(test_text.strip(), include_types=True)
    first_ner_time = time.time() - start_time
    results["first_ner"] = first_ner_time
    print(f"   ç¬¬ä¸€æ¬¡NER: {first_ner_time:.3f}ç§’, è¯†åˆ«{len(entities1)}ä¸ªå®ä½“")

    # ç¬¬äºŒæ¬¡NERè°ƒç”¨ï¼ˆç¼“å­˜å‘½ä¸­ï¼‰
    print("\nğŸ¯ ç¬¬äºŒæ¬¡NERè°ƒç”¨ï¼ˆæµ‹è¯•ç¼“å­˜ï¼‰...")
    start_time = time.time()
    entities2 = fast_adapter.extract_entities(test_text.strip(), include_types=True)
    second_ner_time = time.time() - start_time
    results["second_ner"] = second_ner_time
    print(f"   ç¬¬äºŒæ¬¡NER: {second_ner_time:.3f}ç§’, è¯†åˆ«{len(entities2)}ä¸ªå®ä½“")

    # ç¼“å­˜æ•ˆæœ
    cache_savings = first_ner_time - second_ner_time
    print(
        f"   ğŸ‰ ç¼“å­˜èŠ‚çœ: {cache_savings:.3f}ç§’ ({cache_savings / first_ner_time * 100:.1f}%)"
    )

    # REè°ƒç”¨
    print("\nğŸ”— REè°ƒç”¨...")
    start_time = time.time()
    relations = fast_adapter.extract_relations(test_text.strip(), entities1)
    re_time = time.time() - start_time
    results["re"] = re_time
    print(f"   RE: {re_time:.3f}ç§’, æŠ½å–{len(relations)}ä¸ªå…³ç³»")

    # ç¬¬äºŒæ¬¡REè°ƒç”¨ï¼ˆç¼“å­˜å‘½ä¸­ï¼‰
    print("\nğŸ¯ ç¬¬äºŒæ¬¡REè°ƒç”¨ï¼ˆæµ‹è¯•ç¼“å­˜ï¼‰...")
    start_time = time.time()
    relations2 = fast_adapter.extract_relations(test_text.strip(), entities1)
    second_re_time = time.time() - start_time
    results["second_re"] = second_re_time
    print(f"   ç¬¬äºŒæ¬¡RE: {second_re_time:.3f}ç§’, æŠ½å–{len(relations2)}ä¸ªå…³ç³»")

    re_cache_savings = re_time - second_re_time
    print(
        f"   ğŸ‰ REç¼“å­˜èŠ‚çœ: {re_cache_savings:.3f}ç§’ ({re_cache_savings / re_time * 100:.1f}%)"
    )

    # ç¼“å­˜ç»Ÿè®¡
    cache_stats = fast_adapter.get_cache_stats()
    print(f"\nğŸ’¾ ç¼“å­˜ç»Ÿè®¡: {cache_stats}")

    # è¿æ¥å¤ç”¨æµ‹è¯•
    print("\nğŸ”— è¿æ¥å¤ç”¨æµ‹è¯•ï¼ˆè¿ç»­3æ¬¡çŸ­è°ƒç”¨ï¼‰...")
    short_text = "æµ‹è¯•è¿æ¥å¤ç”¨ã€‚"
    times = []

    for i in range(3):
        start_time = time.time()
        entities = fast_adapter.extract_entities(short_text, include_types=True)
        call_time = time.time() - start_time
        times.append(call_time)
        print(f"   ç¬¬{i + 1}æ¬¡: {call_time:.3f}ç§’")

    avg_time = sum(times) / len(times)
    variance = max(times) - min(times)

    print(f"   å¹³å‡: {avg_time:.3f}ç§’, å˜å¼‚æ€§: {variance:.3f}ç§’")

    # æ€§èƒ½æ€»ç»“
    total_with_cache = (
        results["first_ner"]
        + results["second_ner"]
        + results["re"]
        + results["second_re"]
    )
    total_without_cache = (results["first_ner"] * 2) + (results["re"] * 2)  # æ¨¡æ‹Ÿæ— ç¼“å­˜

    print(f"\nğŸ“Š æ€§èƒ½æ€»ç»“")
    print("=" * 50)
    print(f"é«˜æ€§èƒ½é€‚é…å™¨ï¼ˆå¸¦ç¼“å­˜ï¼‰:")
    print(f"  ç¬¬ä¸€æ¬¡NER:      {results['first_ner']:.3f}ç§’")
    print(f"  ç¬¬äºŒæ¬¡NER:      {results['second_ner']:.3f}ç§’ (ç¼“å­˜)")
    print(f"  ç¬¬ä¸€æ¬¡RE:       {results['re']:.3f}ç§’")
    print(f"  ç¬¬äºŒæ¬¡RE:       {results['second_re']:.3f}ç§’ (ç¼“å­˜)")
    print(f"  æ€»è€—æ—¶:         {total_with_cache:.3f}ç§’")

    print(f"\nå¯¹æ¯”æ— ç¼“å­˜åœºæ™¯:")
    print(f"  æ¨¡æ‹Ÿæ— ç¼“å­˜æ€»è€—æ—¶: {total_without_cache:.3f}ç§’")
    print(f"  ç¼“å­˜èŠ‚çœ:        {total_without_cache - total_with_cache:.3f}ç§’")
    print(
        f"  æ€§èƒ½æå‡:        {(total_without_cache - total_with_cache) / total_without_cache * 100:.1f}%"
    )

    print(f"\nğŸ¯ å…³é”®æ”¹è¿›")
    print("-" * 50)
    print(
        f"âœ… ç¼“å­˜æœºåˆ¶: NERèŠ‚çœ{cache_savings / first_ner_time * 100:.1f}%, REèŠ‚çœ{re_cache_savings / re_time * 100:.1f}%"
    )
    print(f"âœ… è¿æ¥å¤ç”¨: å˜å¼‚æ€§{variance:.3f}ç§’ï¼ˆæ›´ç¨³å®šçš„è¿æ¥ï¼‰")
    print(f"âœ… é«˜æ€§èƒ½é…ç½®: 500è¿æ¥æ± , 100 keep-aliveè¿æ¥")

    # ä¼°ç®—å¯¹26.9ç§’åŸºçº¿çš„æ”¹è¿›
    baseline_time = 26.9  # ä»ä¹‹å‰çš„åˆ†æ
    estimated_improvement = baseline_time * 0.3  # ä¿å®ˆä¼°è®¡70%æ”¹è¿›

    print(f"\nğŸš€ é¢„æœŸæ•´ä½“æ”¹è¿›ï¼ˆåŸºäº26.9ç§’åŸºçº¿ï¼‰")
    print("-" * 50)
    print(f"å½“å‰åŸºçº¿:        26.9ç§’")
    print(f"ç¼“å­˜ä¼˜åŒ–å:      {total_with_cache:.1f}ç§’")
    print(f"é¢„æœŸæœ€ç»ˆæ€§èƒ½:    {estimated_improvement:.1f}ç§’")
    print(
        f"æ€»ä½“æ”¹è¿›:        {(baseline_time - estimated_improvement) / baseline_time * 100:.0f}%"
    )

    return results


def main():
    """ä¸»å‡½æ•°"""
    try:
        results = test_performance_improvement()

        print(f"\nğŸ‰ é«˜æ€§èƒ½é€‚é…å™¨æµ‹è¯•å®Œæˆï¼")
        print("å…³é”®ä¼˜åŒ–å·²éªŒè¯:")
        print("âœ… HTTPè¿æ¥æ± å’Œkeep-alive")
        print("âœ… SQLiteæœ¬åœ°ç¼“å­˜æœºåˆ¶")
        print("âœ… Tenacityé«˜çº§é‡è¯•ç­–ç•¥")
        print("âœ… 5åˆ†é’Ÿè¶…æ—¶é…ç½®")

        return True

    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback

        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
