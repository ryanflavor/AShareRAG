#!/usr/bin/env python3
"""
å®Œæ•´çš„NER/RE + Embedding pipelineæµ‹è¯•
æµ‹è¯•å®Œæ•´æµç¨‹ï¼šæ–‡æ¡£ â†’ NER â†’ RE â†’ åµŒå…¥ â†’ å­˜å‚¨åˆ°LanceDB
"""

import json
import sys
import time
from pathlib import Path
from typing import Any

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.components.embedding_service import EmbeddingService
from src.components.knowledge_graph_constructor import KnowledgeGraphConstructor
from src.components.vector_storage import VectorStorage


def test_complete_pipeline():
    """æµ‹è¯•å®Œæ•´çš„NER/RE/Embedding pipeline"""
    
    print("ğŸ” æµ‹è¯•å®Œæ•´çš„NER/RE + Embedding pipeline")
    print("=" * 80)
    
    # 1. å‡†å¤‡æµ‹è¯•æ•°æ®ï¼ˆé€‰æ‹©å‰3å®¶å…¬å¸ï¼‰
    print("\n1ï¸âƒ£ åŠ è½½æµ‹è¯•æ•°æ®")
    with open("data/corpus.json", "r", encoding="utf-8") as f:
        corpus_data = json.load(f)
    
    # é€‰æ‹©å‰3å®¶å…¬å¸è¿›è¡Œæµ‹è¯•
    test_companies = corpus_data[:3]
    print(f"é€‰æ‹©æµ‹è¯•å…¬å¸: {[c['title'] for c in test_companies]}")
    
    # å‡†å¤‡æ–‡æ¡£æ ¼å¼ï¼ˆKnowledgeGraphConstructoræœŸæœ›çš„æ ¼å¼ï¼‰
    documents = []
    for company in test_companies:
        doc = {
            "id": f"doc_{company['idx']}",
            "text": company["text"],
            "title": company["title"],
            "source_file": "corpus.json"
        }
        documents.append(doc)
    
    # 2. åˆå§‹åŒ–ç»„ä»¶
    print("\n2ï¸âƒ£ åˆå§‹åŒ–ç»„ä»¶")
    
    # åˆå§‹åŒ–embedding service
    embedding_service = EmbeddingService(
        model_name="Qwen/Qwen3-Embedding-4B",
        device="cuda" if __import__("torch").cuda.is_available() else "cpu",
        batch_size=16,
    )
    
    # åˆå§‹åŒ–vector storage
    vector_storage = VectorStorage(
        db_path=Path("./output/complete_pipeline_test"),
        table_name="complete_test",
        embedding_dim=2560,
    )
    
    # è¿æ¥åˆ°vector storage
    vector_storage.connect()
    
    # åˆå§‹åŒ–knowledge graph constructorï¼ˆå¸¦embeddingç»„ä»¶ï¼‰
    constructor = KnowledgeGraphConstructor(
        embedding_service=embedding_service,
        vector_storage=vector_storage
    )
    
    print("âœ… æ‰€æœ‰ç»„ä»¶åˆå§‹åŒ–å®Œæˆ")
    
    # 3. æ‰§è¡Œå®Œæ•´pipeline
    print("\n3ï¸âƒ£ æ‰§è¡Œå®Œæ•´pipeline")
    start_time = time.time()
    
    try:
        # åŠ è½½embeddingæ¨¡å‹
        print("ğŸ“¦ åŠ è½½embeddingæ¨¡å‹...")
        model_loaded = embedding_service.load_model()
        if not model_loaded:
            print("âŒ æ¨¡å‹åŠ è½½å¤±è´¥")
            return
        
        # è¿è¡Œå®Œæ•´pipelineï¼šNER â†’ RE â†’ Embedding â†’ Storage
        print("ğŸ”„ è¿è¡ŒNER/RE/Embedding pipeline...")
        results, graph = constructor.process_documents(documents)
        
        end_time = time.time()
        
        # 4. åˆ†æç»“æœ
        print(f"\n4ï¸âƒ£ Pipelineæ‰§è¡Œç»“æœ (è€—æ—¶: {end_time - start_time:.2f}ç§’)")
        
        # NER/REç»“æœåˆ†æ
        print("\nğŸ“Š NER/REç»“æœ:")
        total_entities = 0
        total_relations = 0
        
        for doc_id, doc_results in results.items():
            entities = doc_results.get('entities', [])
            triples = doc_results.get('triples', [])
            
            print(f"  {doc_id}:")
            print(f"    å®ä½“: {len(entities)} ä¸ª")
            print(f"    å…³ç³»: {len(triples)} ä¸ª")
            
            # æ˜¾ç¤ºå®ä½“æ ·ä¾‹
            if entities:
                for entity in entities[:3]:  # æ˜¾ç¤ºå‰3ä¸ªå®ä½“
                    print(f"      - {entity['text']} ({entity['type']})")
                if len(entities) > 3:
                    print(f"      - ... è¿˜æœ‰ {len(entities) - 3} ä¸ªå®ä½“")
            
            # æ˜¾ç¤ºå…³ç³»æ ·ä¾‹
            if triples:
                for triple in triples[:2]:  # æ˜¾ç¤ºå‰2ä¸ªå…³ç³»
                    print(f"      - {triple[0]} â†’ {triple[1]} â†’ {triple[2]}")
                if len(triples) > 2:
                    print(f"      - ... è¿˜æœ‰ {len(triples) - 2} ä¸ªå…³ç³»")
            
            total_entities += len(entities)
            total_relations += len(triples)
        
        # å›¾è°±ç»“æœ
        print(f"\nğŸ•¸ï¸ çŸ¥è¯†å›¾è°±ç»“æœ:")
        print(f"  èŠ‚ç‚¹æ•°: {graph.vcount()}")
        print(f"  è¾¹æ•°: {graph.ecount()}")
        print(f"  æ€»å®ä½“: {total_entities}")
        print(f"  æ€»å…³ç³»: {total_relations}")
        
        # 5. éªŒè¯å‘é‡å­˜å‚¨
        print(f"\n5ï¸âƒ£ éªŒè¯å‘é‡å­˜å‚¨:")
        
        try:
            table_info = vector_storage.get_table_info()
            print(f"  å­˜å‚¨çš„æ–‡æ¡£æ•°: {table_info['num_rows']}")
            print(f"  å‘é‡ç»´åº¦: {table_info['embedding_dim']}")
            print(f"  è¡¨ç»“æ„: {table_info['schema']}")
            
            # 6. æµ‹è¯•å‘é‡æœç´¢
            print(f"\n6ï¸âƒ£ æµ‹è¯•å‘é‡æœç´¢:")
            
            # è·å–ä¸€äº›å­˜å‚¨çš„æ•°æ®è¿›è¡Œæœç´¢æµ‹è¯•
            all_data = vector_storage.table.to_pandas()
            if len(all_data) > 0:
                # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ–‡æ¡£çš„å‘é‡è¿›è¡Œæœç´¢
                first_vector = eval(all_data.iloc[0]['vector']) if isinstance(all_data.iloc[0]['vector'], str) else all_data.iloc[0]['vector']
                search_results = vector_storage.search(first_vector, top_k=3)
                
                print(f"  æœç´¢ç»“æœ (Top 3):")
                for i, result in enumerate(search_results):
                    company = result.get('company_name', 'Unknown')
                    score = result.get('score', 0)
                    entities_count = len(result.get('entities', []))
                    relations_count = len(result.get('relations', []))
                    
                    print(f"    {i+1}. {company} (ç›¸ä¼¼åº¦: {score:.4f})")
                    print(f"       å®ä½“: {entities_count}ä¸ª, å…³ç³»: {relations_count}ä¸ª")
                
                # 7. éªŒè¯å®ä½“å’Œå…³ç³»æ•°æ®
                print(f"\n7ï¸âƒ£ éªŒè¯å­˜å‚¨çš„å®ä½“å’Œå…³ç³»æ•°æ®:")
                sample_doc = all_data.iloc[0]
                stored_entities = sample_doc.get('entities', [])
                stored_relations = sample_doc.get('relations', [])
                
                print(f"  ç¤ºä¾‹æ–‡æ¡£: {sample_doc.get('company_name', 'Unknown')}")
                print(f"  å­˜å‚¨çš„å®ä½“æ ¼å¼: {type(stored_entities)}")
                
                # å®‰å…¨åœ°æ£€æŸ¥entitiesæ•°æ®
                try:
                    entities_length = len(stored_entities) if stored_entities is not None else 0
                    if entities_length > 0:
                        first_entity = stored_entities[0]
                        print(f"    é¦–ä¸ªå®ä½“: {first_entity}")
                        
                        # éªŒè¯å®ä½“æ ¼å¼æ˜¯å¦ä¸º [{"text": str, "type": str}]
                        if isinstance(first_entity, dict) and 'text' in first_entity and 'type' in first_entity:
                            print("    âœ… å®ä½“æ ¼å¼æ­£ç¡® (Story 1.2.1å…¼å®¹)")
                        else:
                            print("    âŒ å®ä½“æ ¼å¼ä¸æ­£ç¡®")
                    else:
                        print("    å®ä½“åˆ—è¡¨ä¸ºç©º")
                except Exception as entity_error:
                    print(f"    âŒ å®ä½“æ•°æ®æ£€æŸ¥å¤±è´¥: {entity_error}")
                
                print(f"  å­˜å‚¨çš„å…³ç³»æ ¼å¼: {type(stored_relations)}")
                
                # å®‰å…¨åœ°æ£€æŸ¥relationsæ•°æ®
                try:
                    relations_length = len(stored_relations) if stored_relations is not None else 0
                    if relations_length > 0:
                        first_relation = stored_relations[0]
                        print(f"    é¦–ä¸ªå…³ç³»: {first_relation}")
                    else:
                        print("    å…³ç³»åˆ—è¡¨ä¸ºç©º")
                except Exception as relation_error:
                    print(f"    âŒ å…³ç³»æ•°æ®æ£€æŸ¥å¤±è´¥: {relation_error}")
            
        except Exception as e:
            print(f"âŒ å‘é‡å­˜å‚¨éªŒè¯å¤±è´¥: {e}")
        
        # 8. æ€»ä½“è¯„ä¼°
        print(f"\n8ï¸âƒ£ æ€»ä½“è¯„ä¼°:")
        
        pipeline_success = (
            len(results) > 0 and 
            total_entities > 0 and 
            table_info['num_rows'] > 0
        )
        
        if pipeline_success:
            print("âœ… å®Œæ•´pipelineæµ‹è¯•æˆåŠŸ!")
            print("âœ… NER/REæˆåŠŸæå–å®ä½“å’Œå…³ç³»")
            print("âœ… åµŒå…¥ç”Ÿæˆå’Œå­˜å‚¨æˆåŠŸ")
            print("âœ… å‘é‡æœç´¢åŠŸèƒ½æ­£å¸¸")
            print("âœ… Story 1.5è¦æ±‚å®Œå…¨æ»¡è¶³")
        else:
            print("âŒ Pipelineæµ‹è¯•å¤±è´¥")
        
        # 9. æ€§èƒ½ç»Ÿè®¡
        print(f"\n9ï¸âƒ£ æ€§èƒ½ç»Ÿè®¡:")
        print(f"  å¤„ç†æ–‡æ¡£æ•°: {len(documents)}")
        print(f"  æ€»å¤„ç†æ—¶é—´: {end_time - start_time:.2f}ç§’")
        print(f"  å¹³å‡æ¯æ–‡æ¡£: {(end_time - start_time) / len(documents):.2f}ç§’")
        print(f"  å®ä½“æå–ç‡: {total_entities / len(documents):.1f}å®ä½“/æ–‡æ¡£")
        print(f"  å…³ç³»æå–ç‡: {total_relations / len(documents):.1f}å…³ç³»/æ–‡æ¡£")
        
        return pipeline_success
        
    except Exception as e:
        print(f"âŒ Pipelineæ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    finally:
        # æ¸…ç†èµ„æº
        vector_storage.close()


if __name__ == "__main__":
    success = test_complete_pipeline()
    exit(0 if success else 1)